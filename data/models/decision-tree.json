{
  "id": "decision-tree",
  "name": "Decision Tree",
  "aliases": [],
  "category": "Classification/Regression",
  "tags": [
    "tree",
    "nonlinear",
    "classification"
  ],
  "level": "beginner",
  "summary": "Greedy, recursive partitioning to minimize impurity (classification) or variance (regression); highly interpretable leaf rules.",
  "app_scenarios": [
    "Medical diagnosis",
    "Risk assessment",
    "Segmentation"
  ],
  "math": {
    "core_formula": "Gini = 1 - \\sum p_i^2 \\quad \\text{or} \\quad Entropy = -\\sum p_i \\log p_i",
    "derivation": [
      "\\Delta i = i(parent)-p_L i(L)-p_R i(R)",
      "i=\\text{Gini} \\text{ or Entropy}"
    ],
    "assumptions": [
      "Axis-aligned splits capture structure"
    ],
    "constraints": [],
    "variants": [
      "CART",
      "C4.5",
      "CHAID"
    ]
  },
  "hyperparameters": [
    {
      "name": "max_depth",
      "type": "int",
      "default": null,
      "tips": "Limit to prevent overfitting"
    },
    {
      "name": "min_samples_leaf",
      "type": "int",
      "default": 1,
      "tips": "Increase for smoother trees"
    }
  ],
  "data_requirements": {
    "input": "Categorical or continuous features; Minimal preprocessing",
    "scale_sensitivity": "",
    "missing_values": ""
  },
    "required_columns": [
    {"role":"feature_x","canonical":"x","aliases":["X"],"dtype":"number","description":"Feature"},
    {"role":"feature_y","canonical":"y","aliases":["Y"],"dtype":"number","description":"Feature"},
    {"role":"label","canonical":"label","aliases":["target"],"dtype":"number","description":"Class label"}
  ],
  "code": {
    "python_sklearn": "import pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\n\ndf = pd.read_csv('data.csv')\nX = df[['x','y']]; y = df['label']\nmodel = DecisionTreeClassifier().fit(X,y)\n\nprint('score=', model.score(X,y))\npd.DataFrame({'pred':model.predict(X)}).to_csv('result.csv', index=False)"
  },
  "usage": {
    "workflow": [
      "Preprocess features (handle categoricals)",
      "Choose criterion (gini/entropy)",
      "Tune depth/leaves via CV",
      "Prune or use min_cost_complexity_pruning"
    ],
    "examples": []
  },
  "evaluation": {
    "metrics": [
      "Accuracy",
      "Gini/Entropy",
      "MAE/MSE (regression)"
    ],
    "validation": "Stratified CV with early stopping on validation score",
    "baselines": [
      "Logistic Regression (classification)",
      "Linear Regression (regression)"
    ]
  },
  "strengths": [
    "Interpretable",
    "Captures nonlinearity and interactions"
  ],
  "weaknesses": [
    "Prone to overfitting",
    "Unstable to small changes"
  ],
  "pitfalls": [
    "Overfitting without constraints",
    "Instability to small data changes"
  ],
  "comparisons": [
    {
      "with": "Random Forest",
      "differences": [
        "RF averages many trees to reduce variance at cost of interpretability"
      ]
    }
  ],
  "visualizations": [
    "Tree plot",
    "feature importance",
    "Tree diagram",
    "Feature importance"
  ],
  "references": [
    {
      "title": "https://en.wikipedia.org/wiki/Decision_tree_learning",
      "url": "https://en.wikipedia.org/wiki/Decision_tree_learning",
      "type": "docs"
    },
    {
      "title": "https://scikit-learn.org/stable/modules/tree.html",
      "url": "https://scikit-learn.org/stable/modules/tree.html",
      "type": "docs"
    }
  ],
  "related": [
    "scikit-learn",
    "graphviz"
  ],
  "last_updated": "2025-08-24"
}