{
  "id": "random-forest",
  "name": "Random Forest",
  "aliases": [],
  "category": "Ensemble",
  "tags": [
    "ensemble",
    "bagging",
    "tree"
  ],
  "level": "beginner",
  "summary": "Bagging of decision trees with feature randomness; strong, robust baseline on tabular data.",
  "app_scenarios": [
    "Tabular classification",
    "Feature importance analysis"
  ],
  "math": {
    "core_formula": "\\hat{f}(x) = \\frac{1}{B} \\sum_{b=1}^B T_b(x)",
    "derivation": [
      "Bootstrap sample each tree",
      "Random subset of features per split",
      "Averaging reduces variance"
    ],
    "assumptions": [
      "Trees are high-variance learners; bagging helps"
    ],
    "constraints": [],
    "variants": [
      "Extremely Randomized Trees",
      "Isolation Forest"
    ]
  },
  "hyperparameters": [
    {
      "name": "n_estimators",
      "type": "int",
      "default": 200,
      "tips": "Increase for stability until OOB converges"
    },
    {
      "name": "max_depth",
      "type": "int",
      "default": null,
      "tips": "Control overfitting"
    }
  ],
  "data_requirements": {
    "input": "Little feature engineering; Handle missing with care",
    "scale_sensitivity": "",
    "missing_values": ""
  },
  "required_columns": [
    {"role":"feature_x","canonical":"x","aliases":["X"],"dtype":"number","description":"Feature"},
    {"role":"feature_y","canonical":"y","aliases":["Y"],"dtype":"number","description":"Feature"},
    {"role":"label","canonical":"label","aliases":["target"],"dtype":"number","description":"Class label"}
  ],
  "code": {
  "python_sklearn": "import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\n\ndf = pd.read_csv('data.csv')\nX = df[['x','y']]; y = df['label']\nmodel = RandomForestClassifier().fit(X,y)\n\nprint('score=', model.score(X,y))\npd.DataFrame({'pred':model.predict(X)}).to_csv('result.csv', index=False)"
  },
  "usage": {
    "workflow": [
      "Set n_estimators (â‰¥200)",
      "Tune max_depth/min_samples_leaf",
      "Use OOB score for quick validation",
      "Inspect permutation importance/SHAP"
    ],
    "examples": []
  },
  "evaluation": {
    "metrics": [
      "Accuracy",
      "OOB score",
      "ROC-AUC"
    ],
    "validation": "OOB + held-out test",
    "baselines": [
      "Single Decision Tree"
    ]
  },
  "strengths": [
    "Strong baseline",
    "Robust to overfitting",
    "Handles mixed features"
  ],
  "weaknesses": [
    "Less interpretable than a single tree",
    "Larger models"
  ],
  "pitfalls": [
    "Data leakage via target encoding in CV",
    "Bias against rare categories unless encoded"
  ],
  "comparisons": [
    {
      "with": "Gradient Boosting",
      "differences": [
        "RF reduces variance; boosting reduces bias via sequential fitting"
      ]
    }
  ],
  "visualizations": [
    "Feature importance",
    "partial dependence plots",
    "Permutation importance",
    "Partial dependence"
  ],
  "references": [
    {
      "title": "https://en.wikipedia.org/wiki/Random_forest",
      "url": "https://en.wikipedia.org/wiki/Random_forest",
      "type": "docs"
    },
    {
      "title": "https://scikit-learn.org/stable/modules/ensemble.html#random-forests",
      "url": "https://scikit-learn.org/stable/modules/ensemble.html#random-forests",
      "type": "docs"
    }
  ],
  "related": [
    "scikit-learn"
  ],
  "last_updated": "2025-08-24"
}